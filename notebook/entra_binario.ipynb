{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asfRC48B3cr8"
      },
      "source": [
        "En este notebook se hara el proceso de **PRIORIZAR** , se tomaran las PQR Desde diciembre del 2022 a  **2023 a Marzo(periodo de tres meses)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFjCIGvRLWHN"
      },
      "source": [
        "# CONFIGURAR SPARK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sys\n",
        "sys.path.append('../librerias')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdSySf-J3Oiy"
      },
      "source": [
        "# LIBRERIAS\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5v3kkbvVU9pJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-07-07 14:44:42.721607: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-07 14:44:43.765467: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting es-core-news-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.5.0/es_core_news_sm-3.5.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from es-core-news-sm==3.5.0) (3.5.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (1.10.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.1.3)\n",
            "Installing collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "2023-07-07 14:44:57.153155: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-07 14:44:58.323073: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting es-core-news-lg==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_lg-3.5.0/es_core_news_lg-3.5.0-py3-none-any.whl (568.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m568.0/568.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from es-core-news-lg==3.5.0) (3.5.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-lg==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-lg==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-lg==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-lg==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-lg==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-lg==3.5.0) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-lg==3.5.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-lg==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-lg==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-lg==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-lg==3.5.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-lg==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-lg==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-lg==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-lg==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-lg==3.5.0) (1.10.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-lg==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-lg==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-lg==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-lg==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->es-core-news-lg==3.5.0) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-lg==3.5.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-lg==3.5.0) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-lg==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-lg==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->es-core-news-lg==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->es-core-news-lg==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->es-core-news-lg==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->es-core-news-lg==3.5.0) (2.1.3)\n",
            "Installing collected packages: es-core-news-lg\n",
            "Successfully installed es-core-news-lg-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_lg')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download es_core_news_sm\n",
        "\n",
        "!python -m spacy download es_core_news_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HQpIbqTHV86",
        "outputId": "21ef21bc-f152-438d-a8bb-986ebedcc8c8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "import gc\n",
        "\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import sqlite3\n",
        "from sqlite3 import Error\n",
        "import os\n",
        "import re, string\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "#from transformers import AutoTokenizer, BertForSequenceClassification\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import re, string\n",
        "\n",
        "\n",
        "pd.options.display.max_columns = None\n",
        "\n",
        "#from sentence_transformers import SentenceTransformer, util\n",
        "#from transformers import *\n",
        "\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load('es_core_news_sm', disable=['tagger', 'parser', 'ner'])\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "#.master(\"local[2]\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pycorrector\n",
            "  Downloading pycorrector-0.5.0.tar.gz (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from pycorrector) (0.42.1)\n",
            "Collecting pypinyin (from pycorrector)\n",
            "  Downloading pypinyin-0.49.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pycorrector) (1.22.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pycorrector) (1.16.0)\n",
            "Collecting loguru (from pycorrector)\n",
            "  Downloading loguru-0.7.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kenlm (from pycorrector)\n",
            "  Downloading kenlm-0.1.tar.gz (424 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.0/425.0 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pycorrector, kenlm\n",
            "  Building wheel for pycorrector (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycorrector: filename=pycorrector-0.5.0-py3-none-any.whl size=4480931 sha256=85cd8b4e7fa1b2b80b86c623a452f42dfd9b123990c1ef4347ca2e0cdcb30e48\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/cd/34/3c82eb07a21023abd3b8c334a96cb2b8f32cdd986d0f7d0bf4\n",
            "  Building wheel for kenlm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kenlm: filename=kenlm-0.1-cp310-cp310-linux_x86_64.whl size=3003892 sha256=0856279744d26a64f12262778edc1742388e688d6929659b97bb2fd9bfc39359\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/3a/01/9105a071c30781823efbd96a58279c16f948a87cafb1144042\n",
            "Successfully built pycorrector kenlm\n",
            "Installing collected packages: kenlm, pypinyin, loguru, pycorrector\n",
            "Successfully installed kenlm-0.1 loguru-0.7.0 pycorrector-0.5.0 pypinyin-0.49.0\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.6\n",
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.7.2-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.7.2\n"
          ]
        }
      ],
      "source": [
        "%pip install pycorrector\n",
        "%pip install unidecode\n",
        "%pip install pyspellchecker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26MilXbg3TbA"
      },
      "source": [
        "# ETL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "uf-CJREU8cSq"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f8435471-63c6-4dbf-9e82-0bcc69bed0d3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>FECHA_CREACION</th>\n",
              "      <th>NUMERO_PQR</th>\n",
              "      <th>DESCRIPCION_PQR</th>\n",
              "      <th>clasificacion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>22/02/23 9:19</td>\n",
              "      <td>MDM-PQR-37253010</td>\n",
              "      <td>ZULEIMA ALEZANDRA TORRES DIAZ  1031134671 CC  ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>14/02/23 18:20</td>\n",
              "      <td>MDM-PQR-37091363</td>\n",
              "      <td>ZAIDA GUITIERREZ  52325972 CC 6013640557  3209...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3/12/22 8:51</td>\n",
              "      <td>MDM-PQR-35476275</td>\n",
              "      <td>YURY SUAREZ LLANES  51978002 CC  6012169386  3...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>14/02/23 17:18</td>\n",
              "      <td>MDM-PQR-37089931</td>\n",
              "      <td>YULY MORENO  52381328 CC  6012529406  31678196...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>14/02/23 21:44</td>\n",
              "      <td>MDM-PQR-37094750</td>\n",
              "      <td>YULY ANDREA GOMEZ ROMERO  1015467573 CC 314344...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15740</th>\n",
              "      <td>15740</td>\n",
              "      <td>21/02/23 17:11</td>\n",
              "      <td>MDM-PQR-37240623</td>\n",
              "      <td>LINEA NOMBRE JULY ROCIO RIANO RIANO   CED...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15741</th>\n",
              "      <td>15741</td>\n",
              "      <td>10/01/23 13:01</td>\n",
              "      <td>MDM-PQR-36207108</td>\n",
              "      <td>NOMBRE:  YENNY  CEDULA:   51760212 LINE...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15742</th>\n",
              "      <td>15742</td>\n",
              "      <td>15/12/22 11:42</td>\n",
              "      <td>MDM-PQR-35702774</td>\n",
              "      <td>NOMBRE:    EMILSEN CALDERON GARZON   C...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15743</th>\n",
              "      <td>15743</td>\n",
              "      <td>25/02/23 15:29</td>\n",
              "      <td>MDM-PQR-37337458</td>\n",
              "      <td>\"Línea: Nombre de quien se comunica: ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15744</th>\n",
              "      <td>15744</td>\n",
              "      <td>6/12/22 16:02</td>\n",
              "      <td>MDM-PQR-35546962</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15745 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8435471-63c6-4dbf-9e82-0bcc69bed0d3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f8435471-63c6-4dbf-9e82-0bcc69bed0d3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f8435471-63c6-4dbf-9e82-0bcc69bed0d3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       index  FECHA_CREACION        NUMERO_PQR  \\\n",
              "0          0   22/02/23 9:19  MDM-PQR-37253010   \n",
              "1          1  14/02/23 18:20  MDM-PQR-37091363   \n",
              "2          2    3/12/22 8:51  MDM-PQR-35476275   \n",
              "3          3  14/02/23 17:18  MDM-PQR-37089931   \n",
              "4          4  14/02/23 21:44  MDM-PQR-37094750   \n",
              "...      ...             ...               ...   \n",
              "15740  15740  21/02/23 17:11  MDM-PQR-37240623   \n",
              "15741  15741  10/01/23 13:01  MDM-PQR-36207108   \n",
              "15742  15742  15/12/22 11:42  MDM-PQR-35702774   \n",
              "15743  15743  25/02/23 15:29  MDM-PQR-37337458   \n",
              "15744  15744   6/12/22 16:02  MDM-PQR-35546962   \n",
              "\n",
              "                                         DESCRIPCION_PQR  clasificacion  \n",
              "0      ZULEIMA ALEZANDRA TORRES DIAZ  1031134671 CC  ...            1.0  \n",
              "1      ZAIDA GUITIERREZ  52325972 CC 6013640557  3209...            0.0  \n",
              "2      YURY SUAREZ LLANES  51978002 CC  6012169386  3...            1.0  \n",
              "3      YULY MORENO  52381328 CC  6012529406  31678196...            0.0  \n",
              "4      YULY ANDREA GOMEZ ROMERO  1015467573 CC 314344...            0.0  \n",
              "...                                                  ...            ...  \n",
              "15740       LINEA NOMBRE JULY ROCIO RIANO RIANO   CED...            1.0  \n",
              "15741         NOMBRE:  YENNY  CEDULA:   51760212 LINE...            0.0  \n",
              "15742          NOMBRE:    EMILSEN CALDERON GARZON   C...            1.0  \n",
              "15743           \"Línea: Nombre de quien se comunica: ...            1.0  \n",
              "15744                                                  0            0.0  \n",
              "\n",
              "[15745 rows x 5 columns]"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "pandas_c_F= pd.read_csv('/content/PRIORIZAR/entranamiento_/binario_entrenamiento_cruda.csv',delimiter=';')\n",
        "\n",
        "pandas_c_F= pandas_c_F.fillna(0.0)\n",
        "\n",
        "\n",
        "pandas_c_F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "index              0\n",
              "FECHA_CREACION     0\n",
              "NUMERO_PQR         0\n",
              "DESCRIPCION_PQR    0\n",
              "clasificacion      0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pandas_c_F.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "entro2\n"
          ]
        }
      ],
      "source": [
        "from clean_text import clean_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'usuairo queire valdidar  el saldo pendiente'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#declare answers and questions\n",
        "descripcion=pandas_c_F.DESCRIPCION_PQR\t\n",
        "\n",
        "\n",
        "\n",
        "# Cleaning the questions\n",
        "\n",
        "clean_descripcion = []\n",
        "for des in descripcion:\n",
        "    clean_descripcion.append(clean_text(des))\n",
        "\n",
        "\n",
        "#restar dos para optener la data de excel y poder comparar\n",
        "\n",
        "clean_descripcion  [1002]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_descripcion  [15744]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from spelling import correct_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing: 100%|██████████| 15745/15745 [50:19<00:00,  5.21it/s]  \n"
          ]
        }
      ],
      "source": [
        "corrected_sentences = []\n",
        "for text in tqdm(clean_descripcion, desc=\"Processing\"):\n",
        "    corrected_sentence = correct_sentence(text)\n",
        "    corrected_sentences.append(corrected_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "corrected_sentences1=corrected_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ultima alexandra torres diaz cc c incremento en la factura'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corrected_sentences1  [933]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lemastem import data_preprocessing\n",
        "\n",
        "\n",
        "clean_descripcion=data_preprocessing(corrected_sentences1)\n",
        "\n",
        "\n",
        "clean_descripcion[883]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['indicar', 'llego', 'factura', 'monto', 'pagar', 'normalmente']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_descripcion[4379]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "\n",
        "\n",
        "# Specify the file path where you want to save the list\n",
        "file_path = \"/content/PRIORIZAR/data/entrenamiento_binario.pkl\"\n",
        "\n",
        "# Open the file in binary write mode\n",
        "with open(file_path, \"wb\") as file:\n",
        "    # Use the pickle.dump() function to save the list to the file\n",
        "    pickle.dump(clean_descripcion, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Specify the file path from where you want to load the list\n",
        "file_path = \"/content/PRIORIZAR/data/entrenamiento_binario.pkl\"\n",
        "\n",
        "# Open the file in binary read mode\n",
        "with open(file_path, \"rb\") as file:\n",
        "    # Use the pickle.load() function to load the list from the file\n",
        "    loaded_list = pickle.load(file)\n",
        "\n",
        "print(loaded_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "clean_descripcion=loaded_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(clean_descripcion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['saber',\n",
              " 'factura',\n",
              " 'brindar',\n",
              " 'informar',\n",
              " 'adjudicado',\n",
              " 'descuento',\n",
              " 'permanente',\n",
              " 'bajo',\n",
              " 'retirar',\n",
              " 'incremento']"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_descripcion[5668]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "creacion tabla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "pow0vAOrTlgk"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ce709923-61c3-4b40-b0b8-caec49a0fc88\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>descripcion</th>\n",
              "      <th>level_0</th>\n",
              "      <th>index</th>\n",
              "      <th>FECHA_CREACION</th>\n",
              "      <th>NUMERO_PQR</th>\n",
              "      <th>DESCRIPCION_PQR</th>\n",
              "      <th>clasificacion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6596</td>\n",
              "      <td>factura normalmente llegar mil pesos llego aho...</td>\n",
              "      <td>6596</td>\n",
              "      <td>6596</td>\n",
              "      <td>2/12/22 9:04</td>\n",
              "      <td>MDM-PQR-35454208</td>\n",
              "      <td>LINEA: SR-32435621  NOMBRE: JEREMI ALEXANDER M...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>642</td>\n",
              "      <td>concepto facturar</td>\n",
              "      <td>642</td>\n",
              "      <td>642</td>\n",
              "      <td>22/02/23 11:41</td>\n",
              "      <td>MDM-PQR-37259220</td>\n",
              "      <td>WHATSAPP // JUAN SEBASTIAN CAMARGO TORRES // 1...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11000</td>\n",
              "      <td>gustar h pagar factura cada llego factura cost...</td>\n",
              "      <td>11000</td>\n",
              "      <td>11000</td>\n",
              "      <td>1/02/23 15:31</td>\n",
              "      <td>MDM-PQR-36766104</td>\n",
              "      <td>ESPERANZA GUZMAN CAMPOS  39523747 CC  60143659...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10147</td>\n",
              "      <td>beverly ranchero concepto facturar</td>\n",
              "      <td>10147</td>\n",
              "      <td>10147</td>\n",
              "      <td>3/01/23 7:14</td>\n",
              "      <td>MDM-PQR-36046354</td>\n",
              "      <td>JUVERLY LANCHEROS 1024499592 CC 6013101607 310...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5038</td>\n",
              "      <td>solicitar validacion concepto facturar</td>\n",
              "      <td>5038</td>\n",
              "      <td>5038</td>\n",
              "      <td>20/02/23 10:11</td>\n",
              "      <td>MDM-PQR-37197008</td>\n",
              "      <td>Nombre:   JAIDER DAMIAN VILLALBA BONILLA   Céd...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15740</th>\n",
              "      <td>15390</td>\n",
              "      <td>facturacion llego costo factura bajo desear sa...</td>\n",
              "      <td>15390</td>\n",
              "      <td>15390</td>\n",
              "      <td>18/02/23 9:25</td>\n",
              "      <td>MDM-PQR-37168548</td>\n",
              "      <td>LINEA NOMBRE ROSALBA FONSECA BARBOSA   CEDULA...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15741</th>\n",
              "      <td>7158</td>\n",
              "      <td>revisar factura caer llamado</td>\n",
              "      <td>7158</td>\n",
              "      <td>7158</td>\n",
              "      <td>5/12/22 12:39</td>\n",
              "      <td>MDM-PQR-35510878</td>\n",
              "      <td>Linea:   6016314440 Nombre del cliente:  Mauri...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15742</th>\n",
              "      <td>2221</td>\n",
              "      <td>gomezfacturacion</td>\n",
              "      <td>2221</td>\n",
              "      <td>2221</td>\n",
              "      <td>13/02/23 13:04</td>\n",
              "      <td>MDM-PQR-37054877</td>\n",
              "      <td>OLGA GOMEZ GOMEZ/facturacion</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15743</th>\n",
              "      <td>15074</td>\n",
              "      <td>factura</td>\n",
              "      <td>15074</td>\n",
              "      <td>15074</td>\n",
              "      <td>27/01/23 8:24</td>\n",
              "      <td>MDM-PQR-36617424</td>\n",
              "      <td>NOMBRE: RICARDO JOSE ORTEGA VARGAS   CEDULA: ...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15744</th>\n",
              "      <td>2264</td>\n",
              "      <td>confianza cadena factura</td>\n",
              "      <td>2264</td>\n",
              "      <td>2264</td>\n",
              "      <td>11/02/23 14:49</td>\n",
              "      <td>MDM-PQR-37029385</td>\n",
              "      <td>NORMA CONSTANZA LUNA CARDENAS 55064067 CC 6013...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15745 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce709923-61c3-4b40-b0b8-caec49a0fc88')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ce709923-61c3-4b40-b0b8-caec49a0fc88 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ce709923-61c3-4b40-b0b8-caec49a0fc88');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       index                                        descripcion  level_0  \\\n",
              "0       6596  factura normalmente llegar mil pesos llego aho...     6596   \n",
              "1        642                                  concepto facturar      642   \n",
              "2      11000  gustar h pagar factura cada llego factura cost...    11000   \n",
              "3      10147                 beverly ranchero concepto facturar    10147   \n",
              "4       5038             solicitar validacion concepto facturar     5038   \n",
              "...      ...                                                ...      ...   \n",
              "15740  15390  facturacion llego costo factura bajo desear sa...    15390   \n",
              "15741   7158                       revisar factura caer llamado     7158   \n",
              "15742   2221                                   gomezfacturacion     2221   \n",
              "15743  15074                                            factura    15074   \n",
              "15744   2264                           confianza cadena factura     2264   \n",
              "\n",
              "       index  FECHA_CREACION        NUMERO_PQR  \\\n",
              "0       6596    2/12/22 9:04  MDM-PQR-35454208   \n",
              "1        642  22/02/23 11:41  MDM-PQR-37259220   \n",
              "2      11000   1/02/23 15:31  MDM-PQR-36766104   \n",
              "3      10147    3/01/23 7:14  MDM-PQR-36046354   \n",
              "4       5038  20/02/23 10:11  MDM-PQR-37197008   \n",
              "...      ...             ...               ...   \n",
              "15740  15390   18/02/23 9:25  MDM-PQR-37168548   \n",
              "15741   7158   5/12/22 12:39  MDM-PQR-35510878   \n",
              "15742   2221  13/02/23 13:04  MDM-PQR-37054877   \n",
              "15743  15074   27/01/23 8:24  MDM-PQR-36617424   \n",
              "15744   2264  11/02/23 14:49  MDM-PQR-37029385   \n",
              "\n",
              "                                         DESCRIPCION_PQR  clasificacion  \n",
              "0      LINEA: SR-32435621  NOMBRE: JEREMI ALEXANDER M...            1.0  \n",
              "1      WHATSAPP // JUAN SEBASTIAN CAMARGO TORRES // 1...            1.0  \n",
              "2      ESPERANZA GUZMAN CAMPOS  39523747 CC  60143659...            0.0  \n",
              "3      JUVERLY LANCHEROS 1024499592 CC 6013101607 310...            1.0  \n",
              "4      Nombre:   JAIDER DAMIAN VILLALBA BONILLA   Céd...            1.0  \n",
              "...                                                  ...            ...  \n",
              "15740   LINEA NOMBRE ROSALBA FONSECA BARBOSA   CEDULA...            1.0  \n",
              "15741  Linea:   6016314440 Nombre del cliente:  Mauri...            0.0  \n",
              "15742                       OLGA GOMEZ GOMEZ/facturacion            0.0  \n",
              "15743   NOMBRE: RICARDO JOSE ORTEGA VARGAS   CEDULA: ...            0.0  \n",
              "15744  NORMA CONSTANZA LUNA CARDENAS 55064067 CC 6013...            0.0  \n",
              "\n",
              "[15745 rows x 8 columns]"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from unidecode import unidecode\n",
        "\n",
        "\n",
        "\n",
        "merged_data=[]\n",
        "for i in range(len(clean_descripcion)):\n",
        "    merged_data.append(\" \".join(clean_descripcion[i]))\n",
        "\n",
        "merged_df=pd.DataFrame(merged_data,columns =['descripcion']).reset_index()\n",
        "\n",
        "#############################################\n",
        "\n",
        "pandas_c_F.reset_index(inplace=True)\n",
        "\n",
        "#merged_df = pd.merge(merged_df, pandas_c_F, on='index', how='inner').loc[:, ['FECHA_CREACION','NUMERO_PQR','descripcion', 'clasificacion']]\n",
        "\n",
        "merged_df = pd.concat([merged_df, pandas_c_F], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "shuffled_df = merged_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#shuffled_df.rename(columns={\"FECHA_CREACION\": \"event_timestamp\"}, inplace=True)\n",
        "\n",
        "#string_values = ['abcde', 'fghij', 'klmno', 'pqrst', 'uvwxy', 'zabcd', 'efghi', 'jklmn', 'opqrs', 'tuvwx']\n",
        "\n",
        "\n",
        "\n",
        "# Función para eliminar las tildes de un texto\n",
        "def remove_accents(text):\n",
        "    return unidecode(text)\n",
        "\n",
        "# Aplicar la función a la columna 'Texto'\n",
        "shuffled_df['descripcion'] = shuffled_df['descripcion'].apply(remove_accents)\n",
        "\n",
        "\n",
        "\n",
        "# Randomly select string values to fill the DataFrame\n",
        "#random_strings = np.random.choice(string_values, size=len(shuffled_df))\n",
        "\n",
        "#shuffled_df[\"NUMERO_PQR\"]=random_strings\n",
        "shuffled_df['clasificacion'] = shuffled_df['clasificacion'].fillna(0.0)\n",
        "shuffled_df['descripcion'] = shuffled_df['descripcion'].fillna(\"vacio\")\n",
        "\n",
        "shuffled_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "shuffled_df.to_csv('/content/PRIORIZAR/entranamiento_/entrana_bina.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "shuffled_df = pd.read_csv('/content/PRIORIZAR/entranamiento_/entrana_bina.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "index              0\n",
              "descripcion        0\n",
              "level_0            0\n",
              "index              0\n",
              "FECHA_CREACION     0\n",
              "NUMERO_PQR         0\n",
              "DESCRIPCION_PQR    0\n",
              "clasificacion      0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "shuffled_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1., 0.])"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "shuffled_df['clasificacion'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tfidf import TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf-idf with 3614 features\n",
            "train with old features:  (12596, 3614)\n",
            "train with new features: (12596, 804)\n",
            "test with old features:  (3149, 3614)\n",
            "test with new features: (3149, 804)\n",
            "Training Data : (12596, 3614)\n",
            "Testing Data :  (3149, 3614)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['/content/PRIORIZAR/modelo/pca_binario.joblib']"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from joblib import dump\n",
        "\n",
        "\n",
        "\n",
        "X = shuffled_df['descripcion']\n",
        "\n",
        "y = shuffled_df['clasificacion']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# train test split (66% train - 33% test)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=123)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X_train,X_test = TFIDF(X_train,X_test)\n",
        "\n",
        "pca = PCA()\n",
        "\n",
        "pca.fit(X_train)\n",
        "\n",
        "# Get the explained variance ratio for each component\n",
        "explained_variance_ratio = pca.explained_variance_ratio_\n",
        "\n",
        "# Calculate the cumulative explained variance ratio\n",
        "cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n",
        "\n",
        "# Find the number of components that explain a desired amount of variance\n",
        "desired_variance = 0.9  # Set the desired variance threshold\n",
        "n_components = np.argmax(cumulative_variance_ratio >= desired_variance) + 1\n",
        "\n",
        "# Create a new instance of PCA with the optimal number of components\n",
        "pca = PCA(n_components=n_components)\n",
        "\n",
        "\n",
        "X_train_new = pca.fit_transform(X_train)\n",
        "X_test_new = pca.transform(X_test)\n",
        "\n",
        "\n",
        "\n",
        "print(\"train with old features: \",np.array(X_train).shape)\n",
        "print(\"train with new features:\" ,np.array(X_train_new).shape)\n",
        "\n",
        "print(\"test with old features: \",np.array(X_test).shape)\n",
        "print(\"test with new features:\" ,np.array(X_test_new).shape)\n",
        "\n",
        "\n",
        "\n",
        "print('Training Data :', X_train.shape)\n",
        "\n",
        "print('Testing Data : ', X_test.shape)\n",
        "\n",
        "\n",
        "dump(value=pca, filename=\"/content/PRIORIZAR/modelo/pca_binario.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "804"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.11.1)\n",
            "Requirement already satisfied: cmaes>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from optuna) (0.9.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.16)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.65.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.6.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n"
          ]
        }
      ],
      "source": [
        "pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    \"\"\"\n",
        "    Objective function to be minimized.\n",
        "    \"\"\"\n",
        "    param = {\n",
        "        'objective': 'binary',\n",
        "        'metric': 'binary_logloss',\n",
        "        \"verbosity\": -1,\n",
        "        \"boosting_type\": \"gbdt\",\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 80, 300),\n",
        "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-2, 5.0, log=True),\n",
        "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-2, 5.0, log=True),\n",
        "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 30, 90),\n",
        "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
        "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
        "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
        "        'learning_rate': trial.suggest_float(\"learning_rate\", 0.04, 0.1),\n",
        "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    gbm = lgb.LGBMClassifier(**param)\n",
        "    gbm.fit(X_train_new, y_train)\n",
        "    preds = gbm.predict(X_test_new)\n",
        "    accuracy = accuracy_score(y_test, preds)\n",
        "    return accuracy\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-07 15:39:28,112] A new study created in memory with name: lightgbm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] bagging_fraction is set=0.4554031568612787, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4554031568612787\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.010007110473405195, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.010007110473405195\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.879294185249291, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.879294185249291\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.48805353449026784, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48805353449026784\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-07 15:39:46,740] Trial 0 finished with value: 0.7939028262940616 and parameters: {'n_estimators': 172, 'lambda_l1': 0.879294185249291, 'lambda_l2': 0.010007110473405195, 'num_leaves': 48, 'feature_fraction': 0.48805353449026784, 'bagging_fraction': 0.4554031568612787, 'bagging_freq': 2, 'learning_rate': 0.060733643622582864, 'min_child_samples': 43}. Best is trial 0 with value: 0.7939028262940616.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] bagging_fraction is set=0.4164325559187557, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4164325559187557\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7069470359901728, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7069470359901728\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.1353297938831623, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1353297938831623\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9268704618345672, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9268704618345672\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-07 15:40:13,586] Trial 1 finished with value: 0.793585265163544 and parameters: {'n_estimators': 199, 'lambda_l1': 0.1353297938831623, 'lambda_l2': 0.7069470359901728, 'num_leaves': 42, 'feature_fraction': 0.9268704618345672, 'bagging_fraction': 0.4164325559187557, 'bagging_freq': 5, 'learning_rate': 0.06503828814202763, 'min_child_samples': 58}. Best is trial 0 with value: 0.7939028262940616.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] bagging_fraction is set=0.8153935694015885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8153935694015885\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.4493910392244416, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4493910392244416\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.034250741406204634, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.034250741406204634\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5880545068955457, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5880545068955457\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-07 15:40:43,152] Trial 2 finished with value: 0.7942203874245792 and parameters: {'n_estimators': 111, 'lambda_l1': 0.034250741406204634, 'lambda_l2': 1.4493910392244416, 'num_leaves': 89, 'feature_fraction': 0.5880545068955457, 'bagging_fraction': 0.8153935694015885, 'bagging_freq': 7, 'learning_rate': 0.09367639981023085, 'min_child_samples': 13}. Best is trial 2 with value: 0.7942203874245792.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] bagging_fraction is set=0.9747337180903012, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9747337180903012\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.3446621696223424, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.3446621696223424\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.02873208934418634, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02873208934418634\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6526645750030313, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6526645750030313\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-07 15:40:56,725] Trial 3 finished with value: 0.8046999047316609 and parameters: {'n_estimators': 88, 'lambda_l1': 0.02873208934418634, 'lambda_l2': 2.3446621696223424, 'num_leaves': 35, 'feature_fraction': 0.6526645750030313, 'bagging_fraction': 0.9747337180903012, 'bagging_freq': 4, 'learning_rate': 0.0815126268370284, 'min_child_samples': 35}. Best is trial 3 with value: 0.8046999047316609.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] bagging_fraction is set=0.8488993926279036, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8488993926279036\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.011203649455690875, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.011203649455690875\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.7890795571852476, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7890795571852476\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9933166533438968, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9933166533438968\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-07 15:41:57,817] Trial 4 finished with value: 0.7996189266433789 and parameters: {'n_estimators': 231, 'lambda_l1': 1.7890795571852476, 'lambda_l2': 0.011203649455690875, 'num_leaves': 75, 'feature_fraction': 0.9933166533438968, 'bagging_fraction': 0.8488993926279036, 'bagging_freq': 2, 'learning_rate': 0.08735675970708931, 'min_child_samples': 14}. Best is trial 3 with value: 0.8046999047316609.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] bagging_fraction is set=0.41162017472217827, subsample=1.0 will be ignored. Current value: bagging_fraction=0.41162017472217827\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.062009150154225985, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.062009150154225985\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.8331659191517997, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.8331659191517997\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4780171432709666, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4780171432709666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-07 15:42:10,297] Trial 5 finished with value: 0.7824706255954271 and parameters: {'n_estimators': 178, 'lambda_l1': 2.8331659191517997, 'lambda_l2': 0.062009150154225985, 'num_leaves': 47, 'feature_fraction': 0.4780171432709666, 'bagging_fraction': 0.41162017472217827, 'bagging_freq': 5, 'learning_rate': 0.05269768696000354, 'min_child_samples': 30}. Best is trial 3 with value: 0.8046999047316609.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] bagging_fraction is set=0.8198550160125587, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8198550160125587\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.35442650826863986, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.35442650826863986\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.013932335006314283, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.013932335006314283\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7535833221419705, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7535833221419705\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-07 15:42:37,681] Trial 6 finished with value: 0.8043823436011432 and parameters: {'n_estimators': 188, 'lambda_l1': 0.013932335006314283, 'lambda_l2': 0.35442650826863986, 'num_leaves': 38, 'feature_fraction': 0.7535833221419705, 'bagging_fraction': 0.8198550160125587, 'bagging_freq': 1, 'learning_rate': 0.0648433592691741, 'min_child_samples': 71}. Best is trial 3 with value: 0.8046999047316609.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] bagging_fraction is set=0.966756853594488, subsample=1.0 will be ignored. Current value: bagging_fraction=0.966756853594488\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.27949132012721856, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.27949132012721856\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.01364026749788079, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01364026749788079\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7089334672349852, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7089334672349852\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-07 15:43:21,819] Trial 7 finished with value: 0.7869164814226739 and parameters: {'n_estimators': 171, 'lambda_l1': 0.01364026749788079, 'lambda_l2': 0.27949132012721856, 'num_leaves': 70, 'feature_fraction': 0.7089334672349852, 'bagging_fraction': 0.966756853594488, 'bagging_freq': 5, 'learning_rate': 0.09420411491727301, 'min_child_samples': 18}. Best is trial 3 with value: 0.8046999047316609.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] bagging_fraction is set=0.6086595158473039, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6086595158473039\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.11839077252754517, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.11839077252754517\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.510514400536787, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.510514400536787\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9565051482376203, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9565051482376203\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-07 15:43:35,555] Trial 8 finished with value: 0.7970784375992378 and parameters: {'n_estimators': 110, 'lambda_l1': 1.510514400536787, 'lambda_l2': 0.11839077252754517, 'num_leaves': 40, 'feature_fraction': 0.9565051482376203, 'bagging_fraction': 0.6086595158473039, 'bagging_freq': 6, 'learning_rate': 0.0835598791210271, 'min_child_samples': 89}. Best is trial 3 with value: 0.8046999047316609.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] bagging_fraction is set=0.656854713922777, subsample=1.0 will be ignored. Current value: bagging_fraction=0.656854713922777\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.08743114371278075, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08743114371278075\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0635823077784037, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0635823077784037\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9375317309176401, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9375317309176401\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-07 15:44:08,991] Trial 9 finished with value: 0.7821530644649095 and parameters: {'n_estimators': 217, 'lambda_l1': 1.0635823077784037, 'lambda_l2': 0.08743114371278075, 'num_leaves': 46, 'feature_fraction': 0.9375317309176401, 'bagging_fraction': 0.656854713922777, 'bagging_freq': 7, 'learning_rate': 0.07980648986910689, 'min_child_samples': 64}. Best is trial 3 with value: 0.8046999047316609.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] bagging_fraction is set=0.9906203436564979, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9906203436564979\n",
            "[LightGBM] [Warning] lambda_l2 is set=4.077848194578335, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.077848194578335\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.09050182981784267, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09050182981784267\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.40976188344440717, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.40976188344440717\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-07 15:44:30,779] Trial 10 finished with value: 0.8046999047316609 and parameters: {'n_estimators': 289, 'lambda_l1': 0.09050182981784267, 'lambda_l2': 4.077848194578335, 'num_leaves': 32, 'feature_fraction': 0.40976188344440717, 'bagging_fraction': 0.9906203436564979, 'bagging_freq': 3, 'learning_rate': 0.04169914523267015, 'min_child_samples': 38}. Best is trial 3 with value: 0.8046999047316609.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] bagging_fraction is set=0.9561667016544, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9561667016544\n",
            "[LightGBM] [Warning] lambda_l2 is set=4.160462462079653, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.160462462079653\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.06620020325064908, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06620020325064908\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4138867276012137, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4138867276012137\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-07 15:44:54,842] Trial 11 finished with value: 0.802794537948555 and parameters: {'n_estimators': 298, 'lambda_l1': 0.06620020325064908, 'lambda_l2': 4.160462462079653, 'num_leaves': 34, 'feature_fraction': 0.4138867276012137, 'bagging_fraction': 0.9561667016544, 'bagging_freq': 3, 'learning_rate': 0.04089514301599394, 'min_child_samples': 39}. Best is trial 3 with value: 0.8046999047316609.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] bagging_fraction is set=0.9812730229091897, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9812730229091897\n",
            "[LightGBM] [Warning] lambda_l2 is set=4.2105515010394745, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.2105515010394745\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.22351661010466767, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.22351661010466767\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6029867562995748, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6029867562995748\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-07 15:45:26,436] Trial 12 finished with value: 0.7907272149888853 and parameters: {'n_estimators': 299, 'lambda_l1': 0.22351661010466767, 'lambda_l2': 4.2105515010394745, 'num_leaves': 31, 'feature_fraction': 0.6029867562995748, 'bagging_fraction': 0.9812730229091897, 'bagging_freq': 3, 'learning_rate': 0.07642675658148032, 'min_child_samples': 30}. Best is trial 3 with value: 0.8046999047316609.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] bagging_fraction is set=0.8902288478379407, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8902288478379407\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.631987883812238, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.631987883812238\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.04205115657791816, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04205115657791816\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4045786975318669, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4045786975318669\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-07 15:45:52,395] Trial 13 finished with value: 0.7923150206414735 and parameters: {'n_estimators': 255, 'lambda_l1': 0.04205115657791816, 'lambda_l2': 1.631987883812238, 'num_leaves': 58, 'feature_fraction': 0.4045786975318669, 'bagging_fraction': 0.8902288478379407, 'bagging_freq': 4, 'learning_rate': 0.07107992951159499, 'min_child_samples': 47}. Best is trial 3 with value: 0.8046999047316609.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] bagging_fraction is set=0.9894804276742536, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9894804276742536\n",
            "[LightGBM] [Warning] lambda_l2 is set=4.402595285877408, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.402595285877408\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.09988160372788456, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09988160372788456\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6076613405652065, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6076613405652065\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-07 15:46:09,672] Trial 14 finished with value: 0.8005716100349317 and parameters: {'n_estimators': 90, 'lambda_l1': 0.09988160372788456, 'lambda_l2': 4.402595285877408, 'num_leaves': 57, 'feature_fraction': 0.6076613405652065, 'bagging_fraction': 0.9894804276742536, 'bagging_freq': 4, 'learning_rate': 0.04476112706158846, 'min_child_samples': 30}. Best is trial 3 with value: 0.8046999047316609.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] bagging_fraction is set=0.891483419203298, subsample=1.0 will be ignored. Current value: bagging_fraction=0.891483419203298\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.7863799295448113, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7863799295448113\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.4465855488923207, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4465855488923207\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8228828530921526, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8228828530921526\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-07 15:46:28,145] Trial 15 finished with value: 0.803747221340108 and parameters: {'n_estimators': 143, 'lambda_l1': 0.4465855488923207, 'lambda_l2': 1.7863799295448113, 'num_leaves': 30, 'feature_fraction': 0.8228828530921526, 'bagging_fraction': 0.891483419203298, 'bagging_freq': 3, 'learning_rate': 0.05257205262199599, 'min_child_samples': 78}. Best is trial 3 with value: 0.8046999047316609.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] bagging_fraction is set=0.7491374524948881, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7491374524948881\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.7568897309075852, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7568897309075852\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.03076763876483498, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03076763876483498\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5475067474276001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5475067474276001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-07 15:47:10,813] Trial 16 finished with value: 0.7993013655128612 and parameters: {'n_estimators': 256, 'lambda_l1': 0.03076763876483498, 'lambda_l2': 0.7568897309075852, 'num_leaves': 53, 'feature_fraction': 0.5475067474276001, 'bagging_fraction': 0.7491374524948881, 'bagging_freq': 1, 'learning_rate': 0.07378228717350298, 'min_child_samples': 5}. Best is trial 3 with value: 0.8046999047316609.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] bagging_fraction is set=0.9146785624714641, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9146785624714641\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.2245545625463174, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.2245545625463174\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.1844641351258967, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1844641351258967\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6479874005064963, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6479874005064963\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-07 15:47:38,876] Trial 17 finished with value: 0.7862813591616387 and parameters: {'n_estimators': 138, 'lambda_l1': 0.1844641351258967, 'lambda_l2': 2.2245545625463174, 'num_leaves': 73, 'feature_fraction': 0.6479874005064963, 'bagging_fraction': 0.9146785624714641, 'bagging_freq': 2, 'learning_rate': 0.0987527163071957, 'min_child_samples': 49}. Best is trial 3 with value: 0.8046999047316609.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] bagging_fraction is set=0.9971035380270796, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9971035380270796\n",
            "[LightGBM] [Warning] lambda_l2 is set=4.800645487897591, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.800645487897591\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.3780711814912514, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3780711814912514\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5063209798057402, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5063209798057402\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-07 15:48:18,546] Trial 18 finished with value: 0.802794537948555 and parameters: {'n_estimators': 273, 'lambda_l1': 0.3780711814912514, 'lambda_l2': 4.800645487897591, 'num_leaves': 64, 'feature_fraction': 0.5063209798057402, 'bagging_fraction': 0.9971035380270796, 'bagging_freq': 4, 'learning_rate': 0.08225428755418798, 'min_child_samples': 25}. Best is trial 3 with value: 0.8046999047316609.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] bagging_fraction is set=0.9198759476179553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9198759476179553\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.8436284125893285, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8436284125893285\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.10395455935548559, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10395455935548559\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6693568287207703, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6693568287207703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-07 15:48:40,966] Trial 19 finished with value: 0.7916798983804383 and parameters: {'n_estimators': 136, 'lambda_l1': 0.10395455935548559, 'lambda_l2': 0.8436284125893285, 'num_leaves': 86, 'feature_fraction': 0.6693568287207703, 'bagging_fraction': 0.9198759476179553, 'bagging_freq': 4, 'learning_rate': 0.06919327191185369, 'min_child_samples': 99}. Best is trial 3 with value: 0.8046999047316609.\n"
          ]
        }
      ],
      "source": [
        "sampler = TPESampler(seed=1)\n",
        "study = optuna.create_study(study_name=\"lightgbm\", direction=\"maximize\", sampler=sampler)\n",
        "study.optimize(objective, n_trials=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters: {'n_estimators': 88, 'lambda_l1': 0.02873208934418634, 'lambda_l2': 2.3446621696223424, 'num_leaves': 35, 'feature_fraction': 0.6526645750030313, 'bagging_fraction': 0.9747337180903012, 'bagging_freq': 4, 'learning_rate': 0.0815126268370284, 'min_child_samples': 35}\n"
          ]
        }
      ],
      "source": [
        "print('Best parameters:', study.best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.02873208934418634, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02873208934418634\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6526645750030313, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6526645750030313\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.3446621696223424, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.3446621696223424\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9747337180903012, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9747337180903012\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(bagging_fraction=0.9747337180903012, bagging_freq=4,\n",
              "               feature_fraction=0.6526645750030313,\n",
              "               lambda_l1=0.02873208934418634, lambda_l2=2.3446621696223424,\n",
              "               learning_rate=0.0815126268370284, min_child_samples=35,\n",
              "               n_estimators=88, num_leaves=35)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.9747337180903012, bagging_freq=4,\n",
              "               feature_fraction=0.6526645750030313,\n",
              "               lambda_l1=0.02873208934418634, lambda_l2=2.3446621696223424,\n",
              "               learning_rate=0.0815126268370284, min_child_samples=35,\n",
              "               n_estimators=88, num_leaves=35)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LGBMClassifier(bagging_fraction=0.9747337180903012, bagging_freq=4,\n",
              "               feature_fraction=0.6526645750030313,\n",
              "               lambda_l1=0.02873208934418634, lambda_l2=2.3446621696223424,\n",
              "               learning_rate=0.0815126268370284, min_child_samples=35,\n",
              "               n_estimators=88, num_leaves=35)"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mode = lgb.LGBMClassifier(**study.best_params)\n",
        "mode.fit(X_train_new, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = mode.predict(X_test_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.76      0.82      0.79      1394\n",
            "         1.0       0.85      0.79      0.82      1755\n",
            "\n",
            "    accuracy                           0.80      3149\n",
            "   macro avg       0.80      0.81      0.80      3149\n",
            "weighted avg       0.81      0.80      0.81      3149\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/PRIORIZAR/modelo/modelo_binario.joblib']"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from joblib import dump\n",
        "dump(value=mode, filename=\"/content/PRIORIZAR/modelo/modelo_binario.joblib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "para data a predecir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "modelo creacion"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
