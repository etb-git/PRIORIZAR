{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asfRC48B3cr8"
      },
      "source": [
        "En este notebook se hara el proceso de **PRIORIZAR** , se tomaran las PQR Desde diciembre del 2022 a  **2023 a Marzo(periodo de tres meses)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFjCIGvRLWHN"
      },
      "source": [
        "# CONFIGURAR SPARK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sys\n",
        "sys.path.append('../librerias')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdSySf-J3Oiy"
      },
      "source": [
        "# LIBRERIAS\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5v3kkbvVU9pJ"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download es_core_news_sm\n",
        "\n",
        "!python -m spacy download es_core_news_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HQpIbqTHV86",
        "outputId": "21ef21bc-f152-438d-a8bb-986ebedcc8c8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "import gc\n",
        "\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import sqlite3\n",
        "from sqlite3 import Error\n",
        "import os\n",
        "import re, string\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "#from transformers import AutoTokenizer, BertForSequenceClassification\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import re, string\n",
        "\n",
        "\n",
        "pd.options.display.max_columns = None\n",
        "\n",
        "#from sentence_transformers import SentenceTransformer, util\n",
        "#from transformers import *\n",
        "\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load('es_core_news_sm', disable=['tagger', 'parser', 'ner'])\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "#.master(\"local[2]\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install pycorrector\n",
        "%pip install unidecode\n",
        "%pip install pyspellchecker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d2a0ee16-ce19-4292-9f90-124354755d1f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NUMERO_PQR</th>\n",
              "      <th>DESCRIPCION_PQR</th>\n",
              "      <th>prediccion_algoritmo</th>\n",
              "      <th>descripcion_clean</th>\n",
              "      <th>retipificacion_algoritmo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MDM-PQR-39565476</td>\n",
              "      <td>Cliente ARMANDO FARFAN GARZON Cédula de Ciudad...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>factura caer llamado terminar verificacion</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MDM-PQR-39566135</td>\n",
              "      <td>Línea: 6013644591 Nombre: ANA BETRIZ OSORIO CU...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>solicitar saber llegar factura tanto si decir ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MDM-PQR-39566669</td>\n",
              "      <td>Línea: 6016914875 Nombre: SANDRA LUCRECIA MORA...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>solicitar saber costo plan</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MDM-PQR-39566816</td>\n",
              "      <td>Línea: 6012650813 Nombre de quien se comunica:...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>hacer migracion indicar otorgar prorrateo desc...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MDM-PQR-39566871</td>\n",
              "      <td>Línea: SR-35983021 Nombre: REINALDO GONGORA AR...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>solicitar saber llegar factura</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1025</th>\n",
              "      <td>MDM-PQR-39736427</td>\n",
              "      <td>NOMBRE: JOHAN PEÑA CC:1013631526   CORREO:joha...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>saber factura incremento pesos</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1026</th>\n",
              "      <td>MDM-PQR-39736440</td>\n",
              "      <td>NOMBRE: FELIPE ABADIA CC: NIT:901599182 CORREO...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>saber cobrar factura si primero gratuito</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1027</th>\n",
              "      <td>MDM-PQR-39736801</td>\n",
              "      <td>Crear PQRActividades PQRConsulta PQR Cliente J...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>desear validar estar facturar</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1028</th>\n",
              "      <td>MDM-PQR-39736819</td>\n",
              "      <td>Línea: 6014104197   Nombre del Cliente: GUILLE...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>parecer querer saber si aparecer</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1029</th>\n",
              "      <td>MDM-PQR-39736985</td>\n",
              "      <td>NOMBRE: SAMIR MEJIA  CC:79316942 CORREO:zamirt...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ajuste factura falla hacer</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1030 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2a0ee16-ce19-4292-9f90-124354755d1f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d2a0ee16-ce19-4292-9f90-124354755d1f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d2a0ee16-ce19-4292-9f90-124354755d1f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            NUMERO_PQR                                    DESCRIPCION_PQR  \\\n",
              "0     MDM-PQR-39565476  Cliente ARMANDO FARFAN GARZON Cédula de Ciudad...   \n",
              "1     MDM-PQR-39566135  Línea: 6013644591 Nombre: ANA BETRIZ OSORIO CU...   \n",
              "2     MDM-PQR-39566669  Línea: 6016914875 Nombre: SANDRA LUCRECIA MORA...   \n",
              "3     MDM-PQR-39566816  Línea: 6012650813 Nombre de quien se comunica:...   \n",
              "4     MDM-PQR-39566871  Línea: SR-35983021 Nombre: REINALDO GONGORA AR...   \n",
              "...                ...                                                ...   \n",
              "1025  MDM-PQR-39736427  NOMBRE: JOHAN PEÑA CC:1013631526   CORREO:joha...   \n",
              "1026  MDM-PQR-39736440  NOMBRE: FELIPE ABADIA CC: NIT:901599182 CORREO...   \n",
              "1027  MDM-PQR-39736801  Crear PQRActividades PQRConsulta PQR Cliente J...   \n",
              "1028  MDM-PQR-39736819  Línea: 6014104197   Nombre del Cliente: GUILLE...   \n",
              "1029  MDM-PQR-39736985  NOMBRE: SAMIR MEJIA  CC:79316942 CORREO:zamirt...   \n",
              "\n",
              "      prediccion_algoritmo                                  descripcion_clean  \\\n",
              "0                      0.0         factura caer llamado terminar verificacion   \n",
              "1                      0.0  solicitar saber llegar factura tanto si decir ...   \n",
              "2                      0.0                         solicitar saber costo plan   \n",
              "3                      0.0  hacer migracion indicar otorgar prorrateo desc...   \n",
              "4                      0.0                     solicitar saber llegar factura   \n",
              "...                    ...                                                ...   \n",
              "1025                   0.0                     saber factura incremento pesos   \n",
              "1026                   0.0           saber cobrar factura si primero gratuito   \n",
              "1027                   0.0                      desear validar estar facturar   \n",
              "1028                   0.0                   parecer querer saber si aparecer   \n",
              "1029                   0.0                         ajuste factura falla hacer   \n",
              "\n",
              "      retipificacion_algoritmo  \n",
              "0                            0  \n",
              "1                            0  \n",
              "2                            2  \n",
              "3                            1  \n",
              "4                            0  \n",
              "...                        ...  \n",
              "1025                         0  \n",
              "1026                         0  \n",
              "1027                         0  \n",
              "1028                         0  \n",
              "1029                         4  \n",
              "\n",
              "[1030 rows x 5 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read Excel file\n",
        "pandas_c_F = pd.read_excel('/content/PRIORIZAR/entranamiento_/entrenamiento_retipi.xlsx', sheet_name='Sheet1')\n",
        "\n",
        "pandas_c_F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26MilXbg3TbA"
      },
      "source": [
        "# ETL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uf-CJREU8cSq"
      },
      "outputs": [],
      "source": [
        "\n",
        "pandas_c_F= pd.read_csv('/content/PRIORIZAR/entranamiento_/binario_entrenamiento_cruda.csv',delimiter=';')\n",
        "\n",
        "pandas_c_F= pandas_c_F.fillna(\"vacios\")\n",
        "\n",
        "\n",
        "pandas_c_F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pandas_c_F.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "entro2\n"
          ]
        }
      ],
      "source": [
        "from clean_text import clean_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cliente suspende el servicio y le llego factura normal '"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#declare answers and questions\n",
        "descripcion=pandas_c_F.DESCRIPCION_PQR\t\n",
        "\n",
        "\n",
        "\n",
        "# Cleaning the questions\n",
        "\n",
        "clean_descripcion = []\n",
        "for des in descripcion:\n",
        "    clean_descripcion.append(clean_text(des))\n",
        "\n",
        "\n",
        "#restar dos para optener la data de excel y poder comparar\n",
        "\n",
        "clean_descripcion  [1002]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'para ss informacion de facturacion ya que le llego por un valor mayor'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_descripcion  [933]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hola\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "from spelling import correct_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing: 100%|██████████| 1030/1030 [02:16<00:00,  7.57it/s]\n"
          ]
        }
      ],
      "source": [
        "corrected_sentences = []\n",
        "for text in tqdm(clean_descripcion, desc=\"Processing\"):\n",
        "    corrected_sentence = correct_sentence(text)\n",
        "    corrected_sentences.append(corrected_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "corrected_sentences1=corrected_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'para ss informacion de facturacion ya que le llego por un valor mayor'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corrected_sentences1  [933]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['cc', 'tienen', 'estén', 'estar', 'estarían', '\"', 'gmail', 'son', '<', 'tengas', 'feb', '@hotmail', 'hayas', 'de', 'estados', 'habido', 'del', 'míos', 'demá', 'línea', 'algo', 'estáis', 'estuvieran', 'habías', 'fuerais', '{', 'seas', 'hubieras', 'al', 'serás', 'comunica', 'esté', 'noviembre', 'fuisteis', '--', 'tuvieron', 'estamos', 'tuviésemos', 'y', 'angela', 'estuvieseis', 'hubo', 'tendrían', 'habían', 'en', 'estuvimos', 'habrías', 'queda', 'solo', 'estuviéramos', 'septiembre', 'razón', 'este', 'hayáis', '(', 'dg', 'muy', 'que', 'sería', 'hemos', 'hubiéramos', 'sentida', \"''\", 'suyos', 'febrero', 'jose', 'fuimos', 'departamentobogota', 'agosto', 'tengan', 'haya', 'tuyos', 'whats', 'aguirre', 'nuestros', 'estaré', 'había', 'atar', 'sentidos', 'estado', '!', 'junio', 'algunas', 'fueseis', 'ion', 'por', 'enero', 'esos', 'ipc', 'tuyo', 'megas', 'tenía', 'estará', 'rf', 'os', \"'\", 'habría', 'están', 'quienes', 'sobre', 'a', 'uno', 'cedula', 'tendrán', 'habrían', 'sus', 'tuvieses', 'habidos', 'se', 'habrá', '^', 'hubiesen', 'estuviésemos', 'ha', '\\\\', 'has', 'habré', 'tuvisteis', 'fuésemos', 'ellas', 'ti', 'nada', '\"\"', 'estabais', 'tuya', 'sentid', 'etb', 'todo', 'nn', 'seréis', 'in', 'serían', 'pqr', 'ciudadania', 'tiene', 'habrás', 'será', 'int', 'mdmpqr', ':', 'la', ',', 'reply', 'habrán', 'cliente', 'otras', 'poco', 'hubiera', '``', 'serán', 'chat', '-', 'estoy', 'min', 'ftth', '&', 'fuera', 'sr', 'app', 'tus', '‘', 'sí', 'más', 'fueron', 'bytes', ']', 'cortes', 'cual', 'tuviesen', 'f', 'tendríais', 'ok', 'ese', 'linar', 'tuvieran', 'le', '%', 'las', '}', 'com', 'fue', 'tuviste', 'tenías', 'bermuda', 'una', 'manifiesta', 'p', 'vuestro', 'es', 'el', 'hubieseis', ';', 'ms', 'sentidas', 'tened', 'tuvieseis', 'estés', 'estuviese', 'beymar', 'diciembreap', 'fuéramos', 'para', 'teniendo', '?', 'éramos', 'somos', 'seré', 'he', 'antes', 'hra', 'Reportó', 'ref', 'Descripcion', 'hubieran', 'tuviéramos', 'tuvo', 'hotmail', 'tenido', 'tengo', 'tenidas', 'está', 'ttl', 'seq', 'pero', 'teníais', 'seáis', 'sterns', 'vosotros', 'estaríais', '#', 'tenida', 'tendré', 'yo', 'fueran', ')', 'han', 'tuvieras', 'luego', '=', 'what', 'e', 'hay', 'seríais', 'hubiste', 'bis', 'nuestras', 'estuve', 'aaron', 'mi', 'dir', '*', 'un', 'sintiendo', 'estarías', 'ciudadbogota', 'esas', 'cl', 'teníamos', 'tendremos', 'time', 'erais', 'to', 'estaréis', 'mías', 'dirar', 'esto', 'sois', 'estemos', 'tenga', 'su', '+', 'abril', 'tú', 'vuestras', 'edwin', 'gracias', 'porque', 'estas', 'ud', 'te', 'contra', 'otalvaro', 'atención', 'eso', 'indica', 'tenían', 'habidas', 'fueses', 'estada', 'mis', '.', 'habréis', 'tendrás', 'whastapp', 'from', 'tendrá', 'desde', 'hube', 'facebook', 'eres', 'tel', 'unos', 'dire ion', 'donde', '~', 'vuestra', 'habida', 'dirección', 'habremos', 'hayan', 'usuario', 'vuestros', 'habíais', 'era', 'tengamos', 'estos', 'ante', 'cel', 'whast p', 'fuesen', 'otro', 'id', 'hubieron', 'estaba', 'también', 'bot', 'titular', 'alejandro', 'suyo', 'lo', 'hubierais', 'tendría', 'todos', 'estuvieses', 'les', 'estuvo', 'sido', 'hubieses', 'lt', 'estadas', 'max', 'carmona', 'elmer', 'ac', '“', 'co', 'tec', 'tendríamos', 'juan', 'cop', 'hayamos', 'cuando', 'mí', 'estuviste', 'tienes', 'direccion', 'soy', 'ella', 'estuvisteis', 'tengáis', 'saawz', '_', 'aga', 'tu', 'pablo', 'julio', '’', 'estábamos', '>', 'fuese', 'sur', 'comunicación', 'correo', 'habéis', 'octubre', 'ct', 'pi', 'sentido', 'estando', 'Gracias', 'fuiste', 'estuvieras', 'avg', 'preferirnos', 'email', 'mayerli', 'mayo', 'yohana poveda', 'seremos', 'aclara', 'tuvierais', 'estad', 'b', 'nuestro', 'otros', 'whatsapp', 'diciembre', 'estaría', 'ya', 'tendrías', 'algunos', 'sean', '”', '—', 'estarás', 'seríamos', 'tenemos', '/', 'fueras', 'sea', 'cédula', 'marzo', 'hubiésemos', 'estuviesen', 'encuentra', 'estás', 'vosotras', 'o', '`', 'tenidos', '...', 're', 'quien', 'muchos', 'linea', 'estaremos', 'nos', 'estarán', 'habíamos', 'hubisteis', 'tanto', 'última', 'habríamos', 'sur in', 'él', 'menjura', 'esta', 'esa', 'eran', 'seamos', 'mía', 'otra', 'mío', 'suyas', 'tuviera', 'estabas', '[', 'tuviese', 'documento', '@', 'nombre', 'mucho', 'habiendo', 'estaríamos', '$', 'estuvieron', 'tenéis', 'serías', 'sra', 'estuvierais', 'twitter', 'tendréis', 'pineda', 'número', 'tuvimos', 'me', 'eras', 'hasta', 'los', 'como', 'estéis', 'siente', 'fui', 'ellos', 'ap', 'jorge', 'nosotras', 'crm', '|', 'habríais', 'estuviera', 'hubiese', 'nosotros', 'estaban', 'tuve', 'hubimos', 'durante', 'qué', 'mogollon', 'rox', 'nuestra', 'entre', 'tuyas', 'con', 'suya']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['solicitar', 'informacion', 'factura']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from lemastem import data_preprocessing\n",
        "\n",
        "\n",
        "clean_descripcion=data_preprocessing(corrected_sentences1)\n",
        "\n",
        "\n",
        "clean_descripcion[883]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['solicitar', 'informacion', 'factura']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_descripcion[109]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "\n",
        "\n",
        "# Specify the file path where you want to save the list\n",
        "file_path = \"/content/PRIORIZAR/data/entrenamiento_binario.pkl\"\n",
        "\n",
        "# Open the file in binary write mode\n",
        "with open(file_path, \"wb\") as file:\n",
        "    # Use the pickle.dump() function to save the list to the file\n",
        "    pickle.dump(clean_descripcion, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Specify the file path from where you want to load the list\n",
        "file_path = \"/content/PRIORIZAR/data/entrenamiento_binario.pkl\"\n",
        "\n",
        "# Open the file in binary read mode\n",
        "with open(file_path, \"rb\") as file:\n",
        "    # Use the pickle.load() function to load the list from the file\n",
        "    loaded_list = pickle.load(file)\n",
        "\n",
        "print(loaded_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "clean_descripcion=loaded_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(clean_descripcion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_descripcion[5668]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "creacion tabla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pow0vAOrTlgk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from unidecode import unidecode\n",
        "\n",
        "\n",
        "\n",
        "merged_data=[]\n",
        "for i in range(len(clean_descripcion)):\n",
        "    merged_data.append(\" \".join(clean_descripcion[i]))\n",
        "\n",
        "merged_df=pd.DataFrame(merged_data,columns =['descripcion']).reset_index()\n",
        "\n",
        "#############################################\n",
        "\n",
        "pandas_c_F.reset_index(inplace=True)\n",
        "\n",
        "#merged_df = pd.merge(merged_df, pandas_c_F, on='index', how='inner').loc[:, ['FECHA_CREACION','NUMERO_PQR','descripcion', 'clasificacion']]\n",
        "\n",
        "merged_df = pd.concat([merged_df, pandas_c_F], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "shuffled_df = merged_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#shuffled_df.rename(columns={\"FECHA_CREACION\": \"event_timestamp\"}, inplace=True)\n",
        "\n",
        "#string_values = ['abcde', 'fghij', 'klmno', 'pqrst', 'uvwxy', 'zabcd', 'efghi', 'jklmn', 'opqrs', 'tuvwx']\n",
        "\n",
        "\n",
        "\n",
        "# Función para eliminar las tildes de un texto\n",
        "def remove_accents(text):\n",
        "    return unidecode(text)\n",
        "\n",
        "# Aplicar la función a la columna 'Texto'\n",
        "shuffled_df['descripcion'] = shuffled_df['descripcion'].apply(remove_accents)\n",
        "\n",
        "\n",
        "\n",
        "# Randomly select string values to fill the DataFrame\n",
        "#random_strings = np.random.choice(string_values, size=len(shuffled_df))\n",
        "\n",
        "#shuffled_df[\"NUMERO_PQR\"]=random_strings\n",
        "\n",
        "\n",
        "shuffled_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "shuffled_df.to_csv('/content/PRIORIZAR/entranamiento_/entrana_bina.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "shuffled_df = pd.read_csv('/content/PRIORIZAR/entranamiento_/entrana_bina.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tfidf import TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from joblib import dump\n",
        "\n",
        "\n",
        "\n",
        "X = shuffled_df['descripcion']\n",
        "\n",
        "y = shuffled_df['clasificacion']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# train test split (66% train - 33% test)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=123)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X_train,X_test = TFIDF(X_train,X_test)\n",
        "\n",
        "pca = PCA()\n",
        "\n",
        "pca.fit(X_train)\n",
        "\n",
        "# Get the explained variance ratio for each component\n",
        "explained_variance_ratio = pca.explained_variance_ratio_\n",
        "\n",
        "# Calculate the cumulative explained variance ratio\n",
        "cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n",
        "\n",
        "# Find the number of components that explain a desired amount of variance\n",
        "desired_variance = 0.9  # Set the desired variance threshold\n",
        "n_components = np.argmax(cumulative_variance_ratio >= desired_variance) + 1\n",
        "\n",
        "# Create a new instance of PCA with the optimal number of components\n",
        "pca = PCA(n_components=n_components)\n",
        "\n",
        "\n",
        "X_train_new = pca.fit_transform(X_train)\n",
        "X_test_new = pca.transform(X_test)\n",
        "\n",
        "\n",
        "\n",
        "print(\"train with old features: \",np.array(X_train).shape)\n",
        "print(\"train with new features:\" ,np.array(X_train_new).shape)\n",
        "\n",
        "print(\"test with old features: \",np.array(X_test).shape)\n",
        "print(\"test with new features:\" ,np.array(X_test_new).shape)\n",
        "\n",
        "\n",
        "\n",
        "print('Training Data :', X_train.shape)\n",
        "\n",
        "print('Testing Data : ', X_test.shape)\n",
        "\n",
        "\n",
        "dump(value=pca, filename=\"/content/PRIORIZAR/modelo/pca_binario.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    \"\"\"\n",
        "    Objective function to be minimized.\n",
        "    \"\"\"\n",
        "    param = {\n",
        "        'objective': 'binary',\n",
        "        'metric': 'binary_logloss',\n",
        "        \"verbosity\": -1,\n",
        "        \"boosting_type\": \"gbdt\",\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 20, 200),\n",
        "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-2, 5.0, log=True),\n",
        "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-2, 5.0, log=True),\n",
        "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 30, 90),\n",
        "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
        "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
        "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
        "        'learning_rate': trial.suggest_float(\"learning_rate\", 0.04, 0.1),\n",
        "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    gbm = lgb.LGBMClassifier(**param)\n",
        "    gbm.fit(X_train_new, y_train)\n",
        "    preds = gbm.predict(X_test_new)\n",
        "    accuracy = accuracy_score(y_test, preds)\n",
        "    return accuracy\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sampler = TPESampler(seed=1)\n",
        "study = optuna.create_study(study_name=\"lightgbm\", direction=\"maximize\", sampler=sampler)\n",
        "study.optimize(objective, n_trials=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Best parameters:', study.best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mode = lgb.LGBMClassifier(**study.best_params)\n",
        "mode.fit(X_train_new, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = mode.predict(X_test_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from joblib import dump\n",
        "dump(value=mode, filename=\"/content/PRIORIZAR/modelo/modelo_binario.joblib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "para data a predecir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "modelo creacion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpKLHItfhZbG"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "\n",
        "X = shuffled_df['descripcion']\n",
        "\n",
        "y = shuffled_df['clasificacion'].astype(int)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# train test split (66% train - 33% test)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=123)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def TFIDF(X_train, X_test, MAX_NB_WORDS=75000):\n",
        "    vectorizer_x = TfidfVectorizer(max_features=MAX_NB_WORDS)\n",
        "    X_train = vectorizer_x.fit_transform(X_train).toarray()\n",
        "    X_test = vectorizer_x.transform(X_test).toarray()\n",
        "    print(\"tf-idf with\", str(np.array(X_train).shape[1]), \"features\")\n",
        "    return (X_train, X_test)\n",
        "\n",
        "\n",
        "X_train,X_test = TFIDF(X_train,X_test)\n",
        "\n",
        "\n",
        "\n",
        "pca = PCA(n_components=5000)\n",
        "X_train_new = pca.fit_transform(X_train)\n",
        "X_test_new = pca.transform(X_test)\n",
        "\n",
        "print(\"train with old features: \",np.array(X_train).shape)\n",
        "print(\"train with new features:\" ,np.array(X_train_new).shape)\n",
        "\n",
        "print(\"test with old features: \",np.array(X_test).shape)\n",
        "print(\"test with new features:\" ,np.array(X_test_new).shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('Training Data :', X_train.shape)\n",
        "\n",
        "print('Testing Data : ', X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NH4dFMG3j3ZE"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "lr = LogisticRegression()\n",
        "\n",
        "\n",
        "\n",
        "lr.fit(X_train_new, y_train)\n",
        "\n",
        "\n",
        "\n",
        "# generate predictions\n",
        "\n",
        "predictions = lr.predict(X_test_new)\n",
        "\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "from joblib import dump\n",
        "\n",
        "train_data = lgb.Dataset(X_train_new, label=y_train)\n",
        "\n",
        "# Set hyperparameters for LightGBM\n",
        "params = {\n",
        "    'objective': 'binary',\n",
        "    'metric': 'binary_logloss',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 31,\n",
        "    'learning_rate': 0.05,\n",
        "    'feature_fraction': 0.9,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 5,\n",
        "    'verbose': -1\n",
        "}\n",
        "\n",
        "# Train the LightGBM model\n",
        "model = lgb.train(params, train_data, num_boost_round=100)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test_new)\n",
        "\n",
        "y_pred_binary = [1 if val >= 0.5 else 0 for val in y_pred]\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred_binary)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "df = pd.DataFrame(metrics.confusion_matrix(y_test,y_pred_binary), index=['OK','WRONG'], columns=['OK','WRONG'])\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dump(value=model, filename=\"model.joblib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "predicciendo data nueva"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "store = FeatureStore(repo_path=\"/my_project/feature_repo/\")\n",
        "\n",
        "t_predict = store.get_saved_dataset(name=\"prediccion_2\").to_df()\n",
        "\n",
        "t_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = merged_df['descripcion']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def TFIDF(X_train, X_test, MAX_NB_WORDS=75000):\n",
        "    vectorizer_x = TfidfVectorizer(max_features=MAX_NB_WORDS)\n",
        "    X_train = vectorizer_x.fit_transform(X_train).toarray()\n",
        "    X_test = vectorizer_x.transform(X_test).toarray()\n",
        "    print(\"tf-idf with\", str(np.array(X_train).shape[1]), \"features\")\n",
        "    return (X_train, X_test)\n",
        "\n",
        "\n",
        "X_train,X_test = TFIDF(X_train,_)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "pca = PCA(n_components=5000)\n",
        "X_train_new = pca.fit_transform(X_train)\n",
        "X_test_new = pca.transform(X_test)\n",
        "\n",
        "print(\"train with old features: \",np.array(X_train).shape)\n",
        "print(\"train with new features:\" ,np.array(X_train_new).shape)\n",
        "\n",
        "print(\"test with old features: \",np.array(X_test).shape)\n",
        "print(\"test with new features:\" ,np.array(X_test_new).shape)\n",
        "\n",
        "\n",
        "\n",
        "print('Training Data :', X_train.shape)\n",
        "\n",
        "print('Testing Data : ', X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_train_new)\n",
        "\n",
        "y_pred_binary = [1 if val >= 0.5 else 0 for val in y_pred]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "pandas_c_F['prediccion_algoritmo'] = y_pred_binary\n",
        "\n",
        "pandas_c_F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pandas_c_F.to_csv('c_facturados.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEhiySj1LlMN"
      },
      "outputs": [],
      "source": [
        "from feast import FeatureStore\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Getting our FeatureStore\n",
        "store = FeatureStore(repo_path=\"/my_project/feature_repo/\")\n",
        "\n",
        "# Code for loading features to online store between two dates\n",
        "\"\"\"store.materialize(\n",
        "    end_date=datetime.now(),\n",
        "    start_date=datetime.now() - timedelta(days=900))\"\"\"\n",
        "\n",
        "# Loading the latest features after a previous materialize call or from the beginning of time\n",
        "#store.materialize_incremental(end_date=datetime.now())\n",
        "\n",
        "\n",
        "store.materialize(\n",
        "    end_date=datetime.now(),\n",
        "    start_date=partida)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "\n",
        "\n",
        "\n",
        "partida=datetime.now() - timedelta(days=60)\n",
        "\n",
        "# Print the future date\n",
        "print(f\"Current Date: {partida}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oM9gHByaPrQI"
      },
      "outputs": [],
      "source": [
        "feast_features = [\n",
        "        \"prediccion:descripcion\"\n",
        "    ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = store.get_online_features(\n",
        "    features=feast_features,    \n",
        "    entity_rows=[{\"NUMERO_PQR\": \"abcde\"}]\n",
        ").to_dict()\n",
        "\n",
        "string_values = ['abcde', 'fghij', 'klmno', 'pqrst', 'uvwxy', 'zabcd', 'efghi', 'jklmn', 'opqrs', 'tuvwx']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features_df = pd.DataFrame.from_dict(data=features)\n",
        "\n",
        "features_df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
