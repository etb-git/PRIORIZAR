{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# auxiliar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting es-core-news-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.5.0/es_core_news_sm-3.5.0-py3-none-any.whl (12.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from es-core-news-sm==3.5.0) (3.5.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (1.22.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.27.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (1.10.9)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (67.7.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (4.6.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->es-core-news-sm==3.5.0) (2.1.3)\n",
      "Installing collected packages: es-core-news-sm\n",
      "Successfully installed es-core-news-sm-3.5.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycorrector\n",
      "  Downloading pycorrector-0.5.0.tar.gz (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from pycorrector) (0.42.1)\n",
      "Collecting pypinyin (from pycorrector)\n",
      "  Downloading pypinyin-0.49.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pycorrector) (1.22.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pycorrector) (1.16.0)\n",
      "Collecting loguru (from pycorrector)\n",
      "  Downloading loguru-0.7.0-py3-none-any.whl (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kenlm (from pycorrector)\n",
      "  Downloading kenlm-0.1.tar.gz (424 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.0/425.0 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: pycorrector, kenlm\n",
      "  Building wheel for pycorrector (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pycorrector: filename=pycorrector-0.5.0-py3-none-any.whl size=4480931 sha256=dbc17e88a82dae410386ea038df9f47b2a2783c832f37b20e168a7a3de8e20f0\n",
      "  Stored in directory: /root/.cache/pip/wheels/03/cd/34/3c82eb07a21023abd3b8c334a96cb2b8f32cdd986d0f7d0bf4\n",
      "  Building wheel for kenlm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for kenlm: filename=kenlm-0.1-cp310-cp310-linux_x86_64.whl size=3003781 sha256=28e065efd67c7444f771c008ebf570e5ee146e279f3e1e061c33d92e2577af8c\n",
      "  Stored in directory: /root/.cache/pip/wheels/4e/3a/01/9105a071c30781823efbd96a58279c16f948a87cafb1144042\n",
      "Successfully built pycorrector kenlm\n",
      "Installing collected packages: kenlm, pypinyin, loguru, pycorrector\n",
      "Successfully installed kenlm-0.1 loguru-0.7.0 pycorrector-0.5.0 pypinyin-0.49.0\n",
      "Collecting unidecode\n",
      "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: unidecode\n",
      "Successfully installed unidecode-1.3.6\n",
      "Collecting pyspellchecker\n",
      "  Downloading pyspellchecker-0.7.2-py3-none-any.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyspellchecker\n",
      "Successfully installed pyspellchecker-0.7.2\n"
     ]
    }
   ],
   "source": [
    "%pip install pycorrector\n",
    "%pip install unidecode\n",
    "%pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-f2569892-0058-4f87-a8bd-30cedaeab5a4\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>NUMERO_PQR</th>\n",
       "      <th>DESCRIPCION_PQR_x</th>\n",
       "      <th>correccion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MDM-PQR-35550339</td>\n",
       "      <td>Linea:6012167591  Nombre de quien se comunica:...</td>\n",
       "      <td>BENEFICIO DE RETENCION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MDM-PQR-35550340</td>\n",
       "      <td>CATHERIN GOMEZ SALAZAR   3017869468   catherin...</td>\n",
       "      <td>BENEFICIO DE RETENCION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>MDM-PQR-35550341</td>\n",
       "      <td>CLIENTE SE COMUNICA DEBIDO A QUE EL SERVICIO D...</td>\n",
       "      <td>BENEFICIO DE RETENCION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>MDM-PQR-35550342</td>\n",
       "      <td>DIVA GONZALEZ 38253180   6012695479  317445637...</td>\n",
       "      <td>BENEFICIO DE RETENCION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>MDM-PQR-35550343</td>\n",
       "      <td>GLORIA AYDEE BELTRAN   51742212   luzca_26@hot...</td>\n",
       "      <td>BENEFICIO DE RETENCION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>1057</td>\n",
       "      <td>MDM-PQR-36544676</td>\n",
       "      <td>de la compmesacion de las fallas de junio</td>\n",
       "      <td>COMPENSACION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>1058</td>\n",
       "      <td>MDM-PQR-36554753</td>\n",
       "      <td>clietne consutla por ajuste de facturacion</td>\n",
       "      <td>COMPENSACION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>1059</td>\n",
       "      <td>MDM-PQR-36721878</td>\n",
       "      <td>Linea: 12054777127 Cedula: 1012396734 Nombre: ...</td>\n",
       "      <td>COMPENSACION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>1060</td>\n",
       "      <td>MDM-PQR-36990299</td>\n",
       "      <td>cliente consulta sus ajustes por fallas de ser...</td>\n",
       "      <td>COMPENSACION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>1061</td>\n",
       "      <td>MDM-PQR-37300962</td>\n",
       "      <td>NOMBRE: SAMIR MEJIA  CC:79316942 CORREO:zamirt...</td>\n",
       "      <td>COMPENSACION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1060 rows × 4 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2569892-0058-4f87-a8bd-30cedaeab5a4')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f2569892-0058-4f87-a8bd-30cedaeab5a4 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f2569892-0058-4f87-a8bd-30cedaeab5a4');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      index        NUMERO_PQR  \\\n",
       "0         0  MDM-PQR-35550339   \n",
       "1         1  MDM-PQR-35550340   \n",
       "2         2  MDM-PQR-35550341   \n",
       "3         3  MDM-PQR-35550342   \n",
       "4         4  MDM-PQR-35550343   \n",
       "...     ...               ...   \n",
       "1055   1057  MDM-PQR-36544676   \n",
       "1056   1058  MDM-PQR-36554753   \n",
       "1057   1059  MDM-PQR-36721878   \n",
       "1058   1060  MDM-PQR-36990299   \n",
       "1059   1061  MDM-PQR-37300962   \n",
       "\n",
       "                                      DESCRIPCION_PQR_x  \\\n",
       "0     Linea:6012167591  Nombre de quien se comunica:...   \n",
       "1     CATHERIN GOMEZ SALAZAR   3017869468   catherin...   \n",
       "2     CLIENTE SE COMUNICA DEBIDO A QUE EL SERVICIO D...   \n",
       "3     DIVA GONZALEZ 38253180   6012695479  317445637...   \n",
       "4     GLORIA AYDEE BELTRAN   51742212   luzca_26@hot...   \n",
       "...                                                 ...   \n",
       "1055          de la compmesacion de las fallas de junio   \n",
       "1056         clietne consutla por ajuste de facturacion   \n",
       "1057  Linea: 12054777127 Cedula: 1012396734 Nombre: ...   \n",
       "1058  cliente consulta sus ajustes por fallas de ser...   \n",
       "1059  NOMBRE: SAMIR MEJIA  CC:79316942 CORREO:zamirt...   \n",
       "\n",
       "                  correccion  \n",
       "0     BENEFICIO DE RETENCION  \n",
       "1     BENEFICIO DE RETENCION  \n",
       "2     BENEFICIO DE RETENCION  \n",
       "3     BENEFICIO DE RETENCION  \n",
       "4     BENEFICIO DE RETENCION  \n",
       "...                      ...  \n",
       "1055            COMPENSACION  \n",
       "1056            COMPENSACION  \n",
       "1057            COMPENSACION  \n",
       "1058            COMPENSACION  \n",
       "1059            COMPENSACION  \n",
       "\n",
       "[1060 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tipificacion=pd.read_csv(\"/content/PRIORIZAR/data/entrana_retipi_7_junio.csv\",delimiter=\";\").drop_duplicates()\n",
    "\n",
    "\n",
    "tipificacion = tipificacion[tipificacion['correccion'] != 'conceptos facturados']\n",
    "\n",
    "tipificacion=tipificacion.reset_index()\n",
    "\n",
    "\n",
    "tipificacion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipificacion['correccion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import gc\n",
    "\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import os\n",
    "import re, string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "#from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import re, string\n",
    "\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "#from sentence_transformers import SentenceTransformer, util\n",
    "#from transformers import *\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('es_core_news_sm', disable=['tagger', 'parser', 'ner'])\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aca empieza el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../librerias')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clean_text import clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#declare answers and questions\n",
    "descripcion=tipificacion.DESCRIPCION_PQR_x\t\n",
    "\n",
    "\n",
    "\n",
    "# Cleaning the questions\n",
    "\n",
    "clean_descripcion = []\n",
    "for des in descripcion:\n",
    "    clean_descripcion.append(clean_text(des))\n",
    "\n",
    "\n",
    "#clean_descripcion=[k for k in clean_descripcion if 'soporte'  in k]\n",
    "\n",
    "clean_descripcion  [881]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spelling import correct_sentence\n",
    "\n",
    "\n",
    "corrected_text_list = [correct_sentence(text) for text in clean_descripcion]\n",
    "clean_descripcion=corrected_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_descripcion[881]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lemma token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lemastem import data_preprocessing\n",
    "\n",
    "\n",
    "clean_descripcion=data_preprocessing(clean_descripcion)\n",
    "clean_descripcion[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data=[]\n",
    "for i in range(len(clean_descripcion)):\n",
    "    merged_data.append(\" \".join(clean_descripcion[i]))\n",
    "\n",
    "merged_df=pd.DataFrame(merged_data,columns =['descripcion'])\n",
    "\n",
    "\n",
    "from unidecode import unidecode\n",
    "\n",
    "def remove_accents(text):\n",
    "    return unidecode(text)\n",
    "\n",
    "\n",
    "# Aplicar la función a la columna 'Texto'\n",
    "merged_df['descripcion'] = merged_df['descripcion'].apply(remove_accents)\n",
    "\n",
    "\n",
    "tipificacion=pd.concat([tipificacion, merged_df], axis=1).loc[:, ['descripcion', 'correccion']]\n",
    "\n",
    "#merged_df = pd.merge(merged_df,leo , on='index', how='inner').loc[:, ['descripcion', 'correccion']]\n",
    "#############################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tipificacion = tipificacion[tipificacion['correccion'] != 'SVAS']\n",
    "\n",
    "\n",
    "tipificacion=tipificacion.dropna()\n",
    "\n",
    "tipificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipificacion.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipificacion['correccion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Assuming you have a DataFrame called 'data' with 'categories' column\n",
    "# where categories are labeled as 1, 2, and 3\n",
    "mapping = {'otros': 0, 'INCREMENTO DE TARIFA': 1, 'ASEGURAMIENTO': 2,  'BENEFICIO DE RETENCION': 3,'compensacin': 4}\n",
    "\n",
    "# Separate features and target variable\n",
    "X = tipificacion.drop('correccion', axis=1)\n",
    "y = tipificacion['correccion'].replace(mapping)\n",
    "\n",
    "# Oversampling using RandomOverSampler\n",
    "oversampler = RandomOverSampler(sampling_strategy='auto')\n",
    "X_resampled, y_resampled = oversampler.fit_resample(X, y)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mapping = {'otros': 0, 'INCREMENTO DE TARIFA': 1, 'ASEGURAMIENTO': 2,  'BENEFICIO DE RETENCION': 3,'compensacin': 4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "crear matriz de numeros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfidf import TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from joblib import dump\n",
    "\n",
    "\n",
    "X = X_resampled['descripcion']\n",
    "\n",
    "y = y_resampled\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train test split (66% train - 33% test)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=123)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train,X_test = TFIDF(X_train,X_test)\n",
    "\n",
    "pca = PCA()\n",
    "\n",
    "pca.fit(X_train)\n",
    "\n",
    "# Get the explained variance ratio for each component\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "# Calculate the cumulative explained variance ratio\n",
    "cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "# Find the number of components that explain a desired amount of variance\n",
    "desired_variance = 0.95  # Set the desired variance threshold\n",
    "n_components = np.argmax(cumulative_variance_ratio >= desired_variance) + 1\n",
    "\n",
    "# Create a new instance of PCA with the optimal number of components\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "\n",
    "X_train_new = pca.fit_transform(X_train)\n",
    "X_test_new = pca.transform(X_test)\n",
    "\n",
    "print(\"train with old features: \",np.array(X_train).shape)\n",
    "print(\"train with new features:\" ,np.array(X_train_new).shape)\n",
    "\n",
    "print(\"test with old features: \",np.array(X_test).shape)\n",
    "print(\"test with new features:\" ,np.array(X_test_new).shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Training Data :', X_train.shape)\n",
    "\n",
    "print('Testing Data : ', X_test.shape)\n",
    "\n",
    "\n",
    "dump(value=pca, filename=\"/content/PRIORIZAR/modelo/pca_retipificacion.joblib\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Objective function to be minimized.\n",
    "    \"\"\"\n",
    "    param = {\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"metric\": \"multi_logloss\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"num_class\": 5,\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 20, 90),\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-2, 5.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-2, 5.0, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 50),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        'learning_rate': trial.suggest_float(\"learning_rate\", 0.04, 0.1),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "    }\n",
    "\n",
    "    \n",
    "    gbm = lgb.LGBMClassifier(**param)\n",
    "    gbm.fit(X_train_new, y_train)\n",
    "    preds = gbm.predict(X_test_new)\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = TPESampler(seed=1)\n",
    "study = optuna.create_study(study_name=\"lightgbm\", direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters:', study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = lgb.LGBMClassifier(**study.best_params)\n",
    "mode.fit(X_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mode.predict(X_test_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(value=mode, filename=\"/content/PRIORIZAR/modelo/retipificacion.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
